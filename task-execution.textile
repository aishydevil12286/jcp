h2. Executing Tasks in Threads

Application goals:
* Low latency
* Graceful degradation as they become overloaded

Choosing task boundaries:
* Independence -- facilitates concurrency
* Small fraction of application's processing capacity

Many server applications offer a natural choice of task boundary

Approaches:
* Executing sequentially
 ** Pros: offers simplicity and safety advantage
 ** Cons: poor latency and thorughput, obviously: IO, computation, serialized requests (one at a time)
Explicitly creating threads for tasks
 ** Pos
  *** Improves latency -- request processing is offloaded from the main loop
  *** Improves throughput if blocking (IO, locking, resources availability) is presented or if server has multiple cores
 ** Cons
  *** Task handling code must be thread safe
  *** CPU overhead: creating a new thread for each request is time consuming
  *** Memory consumption: if not enough cpus, thread stay idle
  *** Limit on the number of available threads
  *** During prototyping or testing problem of too much threads can stay undetected: put a limit

h2. The Executor Framework

Executor framework
* Decouples task handling from it's execution: possible to use different execution policies
* Implementations add hooks for statistics gathering, application management, monitoring

h3. Execution policiy

Execution policiy defines
* In what thread it will be executed
* In what order to exeute tasks
* How many tasks will execute concurrently
* How many tasks can be queued pending execution
* If a task should be rejected because the system is overloaded: who is the victim and how application should be notified
* Actions to be taken before and after execution of a task

Execution policy is a resource management tool, depends on
* computing resources
* quality of service requirements
* ensuring application does not fail of suffer performance problems due to resource exhaustion

h3. Thread pools



lifecycle
delayed/periodic tasks


h2. Finding Exploitable Parallelism