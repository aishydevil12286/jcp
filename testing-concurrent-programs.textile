Concurrent programs have a degree of non-determenism that sequential programs do not, increasing the number of potential interactions and failure modes that need to be planned for and analyzed.

The same techniques for testing correctness and performance in sequential programs can be applied to concurrent programs:
* but the space of things that can go wrong is much larger
* and potential failures may be rare probabilistic occurences rather than determenistic ones

Tests of concurrent classes usually fall into one or all of the classic categories of safety, liveness and performance
* *tests for safety* verify that class's behavior conforms to its specification, they usually take form of testing invariants
 ** this may require locking a concurrent collection for exclusive access
 ** employing some sort of atomic snapshot
 ** or by using "test points" provided by the implementation that let tests asset invariants or execute test code atomically
 ** test code can unfortunately introduce timing or synchronization artifacts that that can mask bugs that might otherwise manifest themselves
* *tests for liveness*
 ** tests for progress and non-progress are hard to quantify -- how do you verify that a method is blocking and not merely running slowly?
 ** how do you test that an algorithm does not deadlock?
* *performance tests*
 ** *throughput tests* a rate at which a set of concurrent tasks is completed
 ** *responsiveness (latency) tests* the delay between a request for and completion of some actiod
 ** *scalability tests* the improvement in throughput (or lack thereof) as more resources are made available

h2. Testing for correctness

Unit testing a concurrent class starts with the same analysis as for a sequential class -- identifying invariants and post-conditions that are amendable for mechanical checking.

h4. Basic unit tests

Write basic unit test for sequential scenarios, assert invariants and post-conditions. These tests can disclose when a problem is not related to concurrency issues.

h4. Testing blocking operations

Testing that a thread blocks is similar to testing wether an exception is thrown: if finishes successfully, then the test failed.

Testing that a method blocks has *two complications*:
* once a method is blocked, you have to unblock it, which can be solved if the method supports interruptions
* waiting until thread is blocked, have to make a decision about how long the few instructions could possibly take

*Instructions*:
* create a new test thread which performs a blocking operation and either registers failure right after (calling fail()) or cathes an *InterruptedException* which is a success
* test thread waits for specified time, interrupts the test thread, joins it and asserts *assertFalse(newThread.isAlive())*
 ** use timed join -- for the case when blocking gets stuck; the scenario when it is useful to subclass Thread
 ** also tests that blocking method throws *InterruptedException* when blocked and interrupted

*Caution*: don't use *Thread.getState* to verify that the thread is actually in *WAITING* or *TIMED_WAITING* states:
* the JVM can choose to implement blocking by spin-waiting
* spurious wakeups from *Object.wait* or *Condition.await* are permitted, a thread in *WAITING* or *TIMED_WAITING* state may transition to *BLOCKED* and then *RUNNABLE*.
* besides all these reasons, it just may take some time for the target thread to settle into a blocking thread.

h4. Testing safety

* Identifying easily checked properties that will, with high probability, fail if something goes wrong.
* Not letting the failure auditing code limit concurrency artificially. It is best if checking the test propety does not require any synchronization.

Testing consumer-producer designs. Check that everything put into a queue comes out of it, and nothing else does.
* Using shadow list: add elements when added to concurrent collection, remove when removed, check that nothing is left.
 ** This approach would distort the scheduling of the test threads because modifying the shadow list would require synchronization
* Compute checksums of the elements that are enqueued and dequeued using an order-sensitive checksum function, and compare them. Test passes if they match
 ** Works best when there is a single producer and consumer
* For multiple producer-consumer scenario. Compute checksums of the elements that are enqueued and dequeued using an order-insensitive checksum function
 ** We can't check order but don't have to when multuple producers and consumers are used
 ** Either multiple checksums must be calculated or a single shared counter used (which may become a bottleneck)
 ** Ensure that the checksums are not guessable by the compiler
  *** Test data must be randomly generated
  *** Provide each thread with custom generator: allows using non-thread safe generators; most are thread-safe and introduce synchronization
  *** Medium quality fast random generator is enough, no need for high quality randomness, only ensure numbers change from run to run (hashCode and nanoTime, for instance)
 ** If threads are short-running and you start a number of threads in a loop, threads run earlier have a head start on those run later, you can get less real interleavings
  *** Use CyclicBarrier, make the worker thread and test driver thread wait the barrier at the beginning and the end of their run.
  *** Scheduling may still run worker threads sequentially
 ** Use a deterministic termination criterion so that no additional interthread communication is needed to figure out when the test is finished
 ** Threads vs cores requirements
  *** Tests should be run on multiprocessor systems
  *** There should be more active threads than CPUs so at any given time some threads are running and some are switched out, reducing the predictability of interactions between threads
 ** It is possible that the test never finishes due to a bug or an exception
  *** Abort tests that do not terminate within some amount of time
  *** Should distinguish between failed tests and "not waited long enough"
  
h4. Testing resource management

Should not only test that
* code adheres to specification (does what it's suppose to do)
* but also that it doesn't do what it's not supposed to, such as leak resources: does not hold resources (objects in memory, threads, file handles, sockets, databases connections, other limited resources)

Make snapshot of heap size, run code under resource test, make new snapshot of heap size, compare sizes. 

h4. Using callbacks

Callbacks to client-provided code are often made at known points in an object's lyfecycle that are good opportunities to assert invariants.

*ThreadPoolExecutor* makes calls to *Runnables* and *ThreadFactory*
* addition threads are created when they are supposed to, not when they are not supposed to (using TestingThreadFactory can accomplish that)
* idle threads get reaped when they are supposed to (custom Thread class could record when threads terminate)
* the correct number of created tests

h4. Generating more interleavings

Besides running tests on multiprocessors system and using more threads than CPUs you can:
* use of *Thread.yield* encourages more context switches during operations that access shared state, though the effectiveness of this aproach is platform specific
* use of *Thread.sleep* is slower but more relieable

h2. Testing for performance

Performance tests:
* seek to measure end-to-end performance metrics for representative use cases
* to select sizings emperically for various numbers of threads, buffer capacities and so on

h4. Building performance tests

* Use *CyclicBarrier* to start and stop worker threads
* Provide it with *Runnable* to measure start when starting and finishing a job on barrier
* Build "normalized throughput"/"number of threads" graph for different parameters

h4. Comparing multiple algorithms

Build performance tests for different algorithms. 

h4. Measuring responsiveness


h2. Avoding performance testing pitfalls

h2. Complementary testing approaches

